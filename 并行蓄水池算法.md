[参考网站](https://ballsandbins.wordpress.com/2014/04/13/distributedparallel-reservoir-sampling/)

>Now let’s consider a distributed environment such as Hadoop where the input stream consists of several sub-streams and each sub-stream is feed to a single work.  How can we extend the simple algorithm to efficiently sample all sub-streams in parallel and still generate k uniform samples from the entire input stream in the end?
>
>Without loss of generality, let us assume there are two sub-streams of size m and n, respectively. Both m and n are far greater than k. In the first step of the algorithm, workers work on their own sub-streams in parallel, using the basic algorithm. When both workers finish their sub-stream traversal, two reservoir lists R and S are generated. In addition, both workers also count the number of items in their own sub-streams during the traversal, and thus m and n are known when R and S are available.
>
>The critical step is to combine the two reservoir lists to get k items out of them. To do this, we assign weights to items according to the sizes of the sub-stream where they were sampled in the first step, and then do a second sampling phase. We run k iterations for this secondary sampling. In each iteration, we flip a random coin such that, with probability $p = m/(m+n)$, we pick one random sample from reservoir list R, and with probability $1-p$, we pick one random sample from reservoir list S. At the end of the k-th iteration, we will get the final reservoir list for the entire stream. This algorithm is described as follows:

```java
for(sub-stream s: sub-streams) do in parallel {
	simple sequential reservoir sampling and count length of s;
}
double p = (double) m / (m+n);
for(int i = 0; i < k; ++i){
	j = rand.nextDouble();
  	if(j <= p)
    	// 需要解决的问题：保证从R中取出的元素不能重复
    	move a random item from R to T;
  	else
    	move a random item from S to T;
}
return T;
```

>It can be shown by induction that in each iteration of the second sampling phase, any item in the entire stream has probability of 1/(m+n) being chosen. Again, by total probability, any item has probability of k/(m+n) being chosen during the execution of the algorithm, and thus the algorithm generates k random samples from the entire stream. The nice part of this algorithm is that it runs in O(max(m,n)) time and uses O(k) in space.
>
>To generalize the algorithm to cases with more than two sub-streams, one only needs to combine reservoirs lists in pairs, which can also be done in parallel. The proof techniques remain the same and thus is omitted.

