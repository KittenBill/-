[参考网站](https://ballsandbins.wordpress.com/2014/04/13/distributedparallel-reservoir-sampling/)

>Now let’s consider a distributed environment such as Hadoop where the input stream consists of several sub-streams and each sub-stream is feed to a single work.  How can we extend the simple algorithm to efficiently sample all sub-streams in parallel and still generate k uniform samples from the entire input stream in the end?
>
>Without loss of generality, let us assume there are two sub-streams of size m and n, respectively. Both m and n are far greater than k. In the first step of the algorithm, workers work on their own sub-streams in parallel, using the basic algorithm. When both workers finish their sub-stream traversal, two reservoir lists R and S are generated. In addition, both workers also count the number of items in their own sub-streams during the traversal, and thus m and n are known when R and S are available.
>
>The critical step is to combine the two reservoir lists to get k items out of them. To do this, we assign weights to items according to the sizes of the sub-stream where they were sampled in the first step, and then do a second sampling phase. We run k iterations for this secondary sampling. In each iteration, we flip a random coin such that, with probability $p = m/(m+n)$, we pick one random sample from reservoir list R, and with probability $1-p$, we pick one random sample from reservoir list S. At the end of the k-th iteration, we will get the final reservoir list for the entire stream. This algorithm is described as follows:

```java
//  只有两个数据流

for(sub-stream s: sub-streams) do in parallel {
	sequential reservoir sampling and count length of data stream;
}
// got sample result R_M and R_N, 
// length of data stream M and N from above

double p = (double) M / M + N;
for(int i = 0; i < k; ++i){
	j = a randomly generated float in [0, 1];
	if(j >= p)
		move a random element from R_M to R_merge;
	else
		move a random element from R_N to R_merge;
}

return R_merge;

```

>It can be shown by induction that in each iteration of the second sampling phase, any item in the entire stream has probability of 1/(m+n) being chosen. Again, by total probability, any item has probability of k/(m+n) being chosen during the execution of the algorithm, and thus the algorithm generates k random samples from the entire stream. The nice part of this algorithm is that it runs in O(max(m,n)) time and uses O(k) in space.
>
>To generalize the algorithm to cases with more than two sub-streams, one only needs to combine reservoirs lists in pairs, which can also be done in parallel. The proof techniques remain the same and thus is omitted.

```java

BlockingQueue<SampleResult> queue;
for(sub-stream s: sub-streams) do in parallel {
	sequential reservoir sampling;
	put one SampleResult into queue;
}

for (i = 1; i <= sub-streams.size - 1; i++){
	create merging thread with behavior{
		SampleResult r1 = take one SampleResult from queue;
		SampleResult r2 = take one SampleResult from queue;

		SampleResult mergeResult = merge(r1, r2);

		put mergeResult back to queue;
	}
}

for (i = 1; i <= sub-streams.size - 1; i++){
	join merging thread[i];
}

SampleResult finalResult = take one SampleResult from queue;
return finalResult;

```